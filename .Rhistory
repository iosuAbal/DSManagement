d = dist(data)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos k=2 clusters claros
# Metodo particional para comprobarlo
calcular_silhouettes_pam(d,15) # El mayor silhouette se obtiene con k=2
#comparemos las particiones obtenidas en ambos casos
k <- 2
pam <- pam(d,2)
particiones <- comparar_particiones(k, hc, pam)
# Vemos que son casi iguales
# Hay un solo elemento que no sale en el mismo cluster
# veamos cual es
particionWard <- particiones[[1]]
particionPam <- particiones[[2]]
rbind(particionWard[particionPam==1]) # todos los ward y los que PAM sean 1
#teniendo en cuenta la particion que nos ha hecho el metodo pam
#interpretamos los datos: Calculamos la media de cada variable en cada cluster
interpretar_clusters(particionPam, data)
############################
# Reducción de las dimensiones
#aplicamos cmdscale
out <- calcular_scree_graph(d, 2)
# La mayor parte de la información está representada con el primer valor
# Información que se retiene en cada caso
q = 1
sum(out$eig[1:q]) / sum(out$eig) # 0.98
q = 2
sum(out$eig[1:q]) / sum(out$eig) # 0.998
# Creamos los dataframe para el grafico
df1 <- data.frame(C1 = out$points[,1], C2 = out$points[,2], Cluster = factor(particionPam), Metodo = "PAM")
df2 <- data.frame(C1 = out$points[,1], C2 = out$points[,2], Cluster = factor(particionWard), Metodo = "Ward")
df_combined <- rbind(df1, df2)
g <- ggplot(df_combined, aes(C1, C2, color = Cluster)) +
geom_point(size = 3) +
geom_point(data = df_combined[51, ], aes(C1, C2), shape = 21, color = "black", size = 3, stroke = 1.5) +
geom_text(data = df_combined[51, ], aes(C1, C2, label = "Ciudad 51"), vjust = -1.5, hjust = 0.5, show.legend = FALSE) +
geom_point(data = df_combined[57+51, ], aes(C1, C2), shape = 21, color = "black", size = 3, stroke = 1.5) +
geom_text(data = df_combined[57+51, ], aes(C1, C2, label = "Ciudad 51"), vjust = -1.5, hjust = 0.5, show.legend = FALSE) +
facet_wrap(~Metodo)
g
#cual es mejor?
#sabemos que entre todos los valores de k posibles para pam, k=2 es el mejor
#pero es mejor pam en 2 cluster, o ward en 2 cluster?
silPam = silhouette(particionPam, d)
plot(silPam) #0.61 de media, hay algunos individuos mal clasificados
silWard = silhouette(particionWard, d)
plot(silWard)#0.61 tambien, pero el cluster 2 es muy malo
View(data)
library(ggplot2)
#setwd("C:/Users/Alex/Desktop/Entrega3")
setwd("C:/UPV/Master/Analisis de datos/Entrega/Entrega3")
data = read.csv("indicedelitos.csv", header=TRUE, sep=" ")
#########################
# FUNCIONES COMUNES #
#########################
?hclust
calcular_dendrograma <- function(d, method="ward.D2"){
hc <- hclust(d, method= method)
plot(hc, hang=-0.1)
return (hc)
}
calcular_silhouettes <- function (d, n=10){
silPam = rep(NA, n)
for(k in 2:n)
{
#pam
p = pam(d, k, nstart=10)$clustering # en PAM hay que pasar la distancia
aux = silhouette(p, d) # aux es una matriz, lo que nosotros buscamos está en la tercera columna
silPam[k] = mean(aux[, 3])#sil_width
}
plot(1:n, silPam, type="b",xlab="Número de clusters", ylab="Silhouette width",ylim = c(0,1))
}
comparar_particiones <- function(k, hcObject, pamObject){
clward = cutree(hcObject, k)
clpam = pamObject$clustering
print(table(clward, clpam))
return(list(clward,clpam))
}
interpretar_clusters <- function(clpam, data){
for(cluster in 1:2)
{
selec = clpam==cluster
aux = apply(data[selec,], 2, function(x){c(mean(x), sd(x))})
cat("\nCluster ", cluster, "\n")
print(aux)
}
}
calcular_scree_graph <- function(d, k_p){
# Utilizando las coordenadas principales...
out = cmdscale(as.dist(d), k=k_p, eig=T, x.ret=T)
# Veamos los valores propios
plot(out$eig, type="b", xlim=c(0,10))
return(out)
}
#########################
# A: Distancia euclidea #
#########################
d = dist(data)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos k=2 clusters claros
# Metodo particional para comprobarlo
calcular_silhouettes(d,15) # El mayor silhouette se obtiene con k=2
pam <- pam(d,2)
# Vemos que son casi iguales
# Hay un solo elemento que no sale en el mismo cluster
# veamos cual es
particionWard <- particiones[[1]]
particionPam <- particiones[[2]]
rbind(particionWard[particionPam==1]) # todos los ward y los que PAM sean 1
#cual es mejor?
#sabemos que entre todos los valores de k posibles para pam, k=2 es el mejor
#pero es mejor pam en 2 cluster, o ward en 2 cluster?
silPam = silhouette(particionPam, d)
plot(silPam) #0.66 de media
silWard = silhouette(particionWard, d)
plot(silWard)#0.65
#teniendo en cuenta la particion que nos ha hecho el metodo pam
#interpretamos los datos: Calculamos la media de cada variable en cada cluster
interpretar_clusters(particionPam, data)
#aplicamos cmdscale
out <- calcular_scree_graph(d, 2)
# La mayor parte de la información está representada con el primer valor
# Información que se retiene en cada caso
q = 1
sum(out$eig[1:q]) / sum(out$eig) # 0.98
q = 2
sum(out$eig[1:q]) / sum(out$eig) # 0.998
# Creamos los dataframe para el grafico
df1 <- data.frame(C1 = out$points[,1], C2 = out$points[,2], Cluster = factor(particionPam), Metodo = "PAM")
df2 <- data.frame(C1 = out$points[,1], C2 = out$points[,2], Cluster = factor(particionWard), Metodo = "Ward")
df_combined <- rbind(df1, df2)
g <- ggplot(df_combined, aes(C1, C2, color = Cluster)) +
geom_point(size = 3) +
geom_point(data = df_combined[51, ], aes(C1, C2), shape = 21, color = "black", size = 3, stroke = 1.5) +
geom_text(data = df_combined[51, ], aes(C1, C2, label = "Ciudad 51"), vjust = -1.5, hjust = 0.5, show.legend = FALSE) +
geom_point(data = df_combined[57+51, ], aes(C1, C2), shape = 21, color = "black", size = 3, stroke = 1.5) +
geom_text(data = df_combined[57+51, ], aes(C1, C2, label = "Ciudad 51"), vjust = -1.5, hjust = 0.5, show.legend = FALSE) +
facet_wrap(~Metodo)
g
############################
# B: distancia correlación #
############################
c = cor(t(data), t(data)) #ponemos individuos en columnas
d = sqrt(1-c)
d = as.dist(d)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos que pueden haber 2 o 3 clusters
# Metodo particional para comprobarlo
calcular_silhouettes(d,15) # Lo mejor es k=10, pero no es viable
#########################
# A: Distancia euclidea #
#########################
d = dist(data)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos k=2 clusters claros
# Metodo particional para comprobarlo
calcular_silhouettes(d,15) # El mayor silhouette se obtiene con k=2
#comparemos las particiones obtenidas para PAM y hclust
k <- 2
pam <- pam(d,2)
particiones <- comparar_particiones(k, hc, pam)
# Vemos que son casi iguales
# Hay un solo elemento que no sale en el mismo cluster
# veamos cual es
particionWard <- particiones[[1]]
particionPam <- particiones[[2]]
rbind(particionWard[particionPam==1]) # todos los ward y los que PAM sean 1
#cual es mejor?
#sabemos que entre todos los valores de k posibles para pam, k=2 es el mejor
#pero es mejor pam en 2 cluster, o ward en 2 cluster?
silPam = silhouette(particionPam, d)
plot(silPam) #0.66 de media
#cual es mejor?
#sabemos que entre todos los valores de k posibles para pam, k=2 es el mejor
#pero es mejor pam en 2 cluster, o ward en 2 cluster?
silPam = silhouette(particionPam, d)
library(cluster)
library(ggplot2)
#setwd("C:/Users/Alex/Desktop/Entrega3")
setwd("C:/UPV/Master/Analisis de datos/Entrega/Entrega3")
data = read.csv("indicedelitos.csv", header=TRUE, sep=" ")
#########################
# FUNCIONES COMUNES #
#########################
?hclust
calcular_dendrograma <- function(d, method="ward.D2"){
hc <- hclust(d, method= method)
plot(hc, hang=-0.1)
return (hc)
}
calcular_silhouettes <- function (d, n=10){
silPam = rep(NA, n)
for(k in 2:n)
{
#pam
p = pam(d, k, nstart=10)$clustering # en PAM hay que pasar la distancia
aux = silhouette(p, d) # aux es una matriz, lo que nosotros buscamos está en la tercera columna
silPam[k] = mean(aux[, 3])#sil_width
}
plot(1:n, silPam, type="b",xlab="Número de clusters", ylab="Silhouette width",ylim = c(0,1))
}
comparar_particiones <- function(k, hcObject, pamObject){
clward = cutree(hcObject, k)
clpam = pamObject$clustering
print(table(clward, clpam))
return(list(clward,clpam))
}
interpretar_clusters <- function(clpam, data){
for(cluster in 1:2)
{
selec = clpam==cluster
aux = apply(data[selec,], 2, function(x){c(mean(x), sd(x))})
cat("\nCluster ", cluster, "\n")
print(aux)
}
}
calcular_scree_graph <- function(d, k_p){
# Utilizando las coordenadas principales...
out = cmdscale(as.dist(d), k=k_p, eig=T, x.ret=T)
# Veamos los valores propios
plot(out$eig, type="b", xlim=c(0,10))
return(out)
}
#########################
# A: Distancia euclidea #
#########################
d = dist(data)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos k=2 clusters claros
# Metodo particional para comprobarlo
calcular_silhouettes(d,15) # El mayor silhouette se obtiene con k=2
#comparemos las particiones obtenidas para PAM y hclust
k <- 2
pam <- pam(d,2)
particiones <- comparar_particiones(k, hc, pam)
# Vemos que son casi iguales
# Hay un solo elemento que no sale en el mismo cluster
# veamos cual es
particionWard <- particiones[[1]]
particionPam <- particiones[[2]]
rbind(particionWard[particionPam==1]) # todos los ward y los que PAM sean 1
#cual es mejor?
#sabemos que entre todos los valores de k posibles para pam, k=2 es el mejor
#pero es mejor pam en 2 cluster, o ward en 2 cluster?
silPam = silhouette(particionPam, d)
plot(silPam) #0.66 de media
plot(silPam, main = 'Plot silhouette: Partición PAM y distancias Euclídeas') #0.66 de media
silWard = silhouette(particionWard, d)
plot(silWard, main = 'Plot silhouette: Partición Ward.D2 y distancias euclídeas')#0.65
#teniendo en cuenta la particion que nos ha hecho el metodo pam
#interpretamos los datos: Calculamos la media de cada variable en cada cluster
interpretar_clusters(particionPam, data)
#aplicamos cmdscale
out <- calcular_scree_graph(d, 2)
# La mayor parte de la información está representada con el primer valor
# Información que se retiene en cada caso
q = 1
sum(out$eig[1:q]) / sum(out$eig) # 0.98
q = 2
sum(out$eig[1:q]) / sum(out$eig) # 0.998
# Creamos los dataframe para el grafico
df1 <- data.frame(C1 = out$points[,1], C2 = out$points[,2], Cluster = factor(particionPam), Metodo = "PAM")
df2 <- data.frame(C1 = out$points[,1], C2 = out$points[,2], Cluster = factor(particionWard), Metodo = "Ward")
df_combined <- rbind(df1, df2)
g <- ggplot(df_combined, aes(C1, C2, color = Cluster)) +
geom_point(size = 3) +
geom_point(data = df_combined[51, ], aes(C1, C2), shape = 21, color = "black", size = 3, stroke = 1.5) +
geom_text(data = df_combined[51, ], aes(C1, C2, label = "Ciudad 51"), vjust = -1.5, hjust = 0.5, show.legend = FALSE) +
geom_point(data = df_combined[57+51, ], aes(C1, C2), shape = 21, color = "black", size = 3, stroke = 1.5) +
geom_text(data = df_combined[57+51, ], aes(C1, C2, label = "Ciudad 51"), vjust = -1.5, hjust = 0.5, show.legend = FALSE) +
facet_wrap(~Metodo)
g
############################
# B: distancia correlación #
############################
c = cor(t(data), t(data)) #ponemos individuos en columnas
d = sqrt(1-c)
d = as.dist(d)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos que pueden haber 2 o 3 clusters
# Metodo particional para comprobarlo
calcular_silhouettes(d,15) # Lo mejor es k=10, pero no es viable
#comparemos las particiones obtenidas en ambos casos
k <- 2
pam <- pam(d,k)
particiones <- comparar_particiones(k, hc, pam)
# En este caso hay 7 individuos clasificados de diferente manera
particionWard <- particiones[[1]]
particionPam <- particiones[[2]]
rbind(particionWard[particionPam==1]) # todos los ward y los que PAM sean 1
#cual es mejor?
#sabemos que entre todos los valores de k posibles para pam, k=2 es el mejor
#pero es mejor pam en 2 cluster, o ward en 2 cluster?
silPam = silhouette(particionPam, d)
plot(silPam) #0.61 de media, hay algunos individuos mal clasificados
silWard = silhouette(particionWard, d)
plot(silWard)#0.61 tambien, pero el cluster 2 es muy malo
#teniendo en cuenta la particion que nos ha hecho el metodo pam
#interpretamos los datos: Calculamos la media de cada variable en cada cluster
interpretar_clusters(particionPam, data)
############################
# Reducción de las dimensiones
#aplicamos cmdscale
out <- calcular_scree_graph(d, 2)
# La mayor parte de la información está representada con el primer valor
# Información que se retiene en cada caso
q = 2
sum(out$eig[1:q])# mantenemos solo un 77% de variabilidad
# Creamos los dataframe para el grafico
df1 <- data.frame(C1 = out$points[,1], C2 = out$points[,2], Cluster = factor(particionPam), Metodo = "PAM")
df2 <- data.frame(C1 = out$points[,1], C2 = out$points[,2], Cluster = factor(particionWard), Metodo = "Ward")
df_combined <- rbind(df1, df2)
g <- ggplot(df_combined, aes(C1, C2, color = Cluster)) +
geom_point(size = 3) +
facet_wrap(~Metodo)
g
############################
# B: distancia correlación #
############################
c = cor(t(data), t(data)) #ponemos individuos en columnas
d = sqrt(1-c)
d = as.dist(d)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos que pueden haber 2 o 3 clusters
# Metodo particional para comprobarlo
calcular_silhouettes(d,15) # Lo mejor es k=10, pero no es viable
calcular_silhouettes <- function (d, n=10){
silPam = rep(NA, n)
for(k in 2:n)
{
#pam
p = pam(d, k, nstart=10)$clustering # en PAM hay que pasar la distancia
aux = silhouette(p, d) # aux es una matriz, lo que nosotros buscamos está en la tercera columna
silPam[k] = mean(aux[, 3])#sil_width
}
plot(1:n, silPam, type="b",main="Índice de silhouette para distintas particiones PAM",xlab="Número de clusters", ylab="Silhouette width")
}
############################
# B: distancia correlación #
############################
c = cor(t(data), t(data)) #ponemos individuos en columnas
d = sqrt(1-c)
d = as.dist(d)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos que pueden haber 2 o 3 clusters
# Metodo particional para comprobarlo
calcular_silhouettes(d,15) # Lo mejor es k=10, pero no es viable
############################
# B: distancia correlación #
############################
c = cor(t(data)) #ponemos individuos en columnas
d = sqrt(1-c)
d = as.dist(d)
############################
# B: distancia correlación #
############################
c = cor(t(data)) #ponemos individuos en columnas
d = sqrt(1-c)
d = as.dist(d)
# ¿Cuántos clusters crear?
# metodo jerarquico
hc <- calcular_dendrograma(d) # Analizando el gráfico vemos que pueden haber 2 o 3 clusters
# Metodo particional para comprobarlo
calcular_silhouettes(d,15) # Lo mejor es k=10, pero no es viable
#comparemos las particiones obtenidas en ambos casos
k <- 3
pam <- pam(d,k)
particiones <- comparar_particiones(k, hc, pam)
# En este caso hay 7 individuos clasificados de diferente manera
particionWard <- particiones[[1]]
particionPam <- particiones[[2]]
rbind(particionWard[particionPam==1]) # todos los ward y los que PAM sean 1
#cual es mejor?
#sabemos que entre todos los valores de k posibles para pam, k=2 es el mejor
#pero es mejor pam en 2 cluster, o ward en 2 cluster?
silPam = silhouette(particionPam, d)
plot(silPam) #0.61 de media, hay algunos individuos mal clasificados
silWard = silhouette(particionWard, d)
plot(silWard)#0.61 tambien, pero el cluster 2 es muy malo
#cual es mejor?
#sabemos que entre todos los valores de k posibles para pam, k=2 es el mejor
#pero es mejor pam en 2 cluster, o ward en 2 cluster?
silPam = silhouette(particionPam, d)
plot(silPam) #0.61 de media, hay algunos individuos mal clasificados
plot(silPam,main = "Plot silhouette: Partición PAM y distancia de correlaciones") #0.61 de media, hay algunos individuos mal clasificados
plot(silWard, main = "Plot silhouette: Partición Ward.D2 y distancia de correlaciones")#0.61 tambien, pero el cluster 2 es muy malo
devtools::build_vignettes()
install.packages('devtools')
devtools::build_vignettes()
devtools::build_vignettes()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
vector <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
atributo <- atributoDataset("Test", vector)
cut_points <- c(5)
discretize(atributo, cut_points)
roxygen2::roxygenize()
vector <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
atributo <- atributoDataset("Test", vector)
cut_points <- c(5)
discretize(atributo, cut_points)
atributo <- atributoDataset("Num", vector)
cut_points <- c(5)
discretize(atributo, cut_points)
numeric_attr <- atributoDataset("Numeric Attribute", c(1, 2, 3, 4, 5))
cut_points <- c(5)
discretize(numeric_attr, cut_points)
numeric_attr <- atributoDataset("Numeric Attribute", "numeric",c(1, 2, 3, 4, 5))
cut_points <- c(5)
discretize(numeric_attr, cut_points)
numeric_attr <- atributoDataset("Numeric Attribute", "integer", c(1, 2, 3, 4, 5))
cut_points <- c(5)
discretize(numeric_attr, cut_points)
numeric_attr <- atributoDataset("Numeric Attribute", c(1, 2, 3, 4, 5))
numeric_attr
cut_points <- c(5)
discretize(numeric_attr, cut_points)
numeric_attr
numeric_attr <- atributoDataset("Numeric Attribute", c(1, 2, 3, 4, 5))
numeric_attr
cut_points <- c(5)
discretize(numeric_attr, cut_points)
numeric_attr <- atributoDataset("Numeric Attribute", c(1, 2, 3, 4, 5))
numeric_attr
cut_points <- c(5)
discretize(numeric_attr, cut_points)
numeric_attr <- atributoDataset(name="Numeric Attribute", vector=c(1, 2, 3, 4, 5))
numeric_attr
cut_points <- c(5)
discretize(numeric_attr, cut_points)
numeric_attr <- atributoDataset("Numeric Attribute", seq(1:20))
discretizeEW(numeric_attr, 3)
discretize(numeric_attr, 3)
numeric_attr <- atributoDataset("Numeric Attribute", seq(1:20))
discretize(numeric_attr, c(1,3))
numeric_attr <- atributoDataset(name="Numeric Attribute", c(1, 2, 3, 4, 5))
numeric_attr
cut_points <- c(5)
discretize(numeric_attr, cut_points)
roxygen2::roxygenize()
roxygen2::roxygenize()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(DSManagement)
library(ggplot2)
library(reshape2)
library(patchwork)
numeric_attr <- atributoDataset("Numeric Attribute", seq(1:20))
discretizeEW(numeric_attr, 3)
#prueba
ds <- datasetFromCSV("../data/fichero.csv")
discretizeEF(ds, 2)
numeric_attr <- atributoDataset("Numeric Attribute", seq(1:20))
logical_attr <- atributoDataset("Logical Attribute", sample(c(FALSE, TRUE), size = 20, replace = TRUE))
my_dataset <- createDataset("My Dataset", list(numeric_attr, logical_attr))
calculateMetrics(my_dataset)
atributo <- atributoDataset(name = "Attribute1", vector = c(1, 2, 3, 4, 5))
normalize(atributo)
dataset <- createDataset(nombre = "Example", atributos = list(
atributoDataset(name = "Numeric1", vector = c(1, 1.5, 3,2, 5)),
atributoDataset(name = "Numeric2", vector = c(21, 31, 60, 76)),
atributoDataset(name = "FactorAttr", vector = factor(c("A", "B", "A", "A")))))
standarize(dataset)
dataset <- createDataset(nombre = "Example", atributos = list(
atributoDataset(name = "NumericAttr", vector = c(1, 2, 3, 4)),
atributoDataset(name = "FactorAttr", vector = factor(c("rojo","verde","verde", "verde"))),
atributoDataset(name = "FactorAttr2", vector = factor(c("rojo","verde","azul","amarillo"))),
atributoDataset(name = "LogicalAttr", vector = (c(FALSE, TRUE, FALSE, TRUE)))
))
newDs <- filterMetrics(dataset,"Entropy","<",1)
newDs
dataset <- createDataset(nombre = "Example", atributos = list(
atributoDataset(name = "NumericAttr", vector = c(1, 2, 3, 4)),
atributoDataset(name = "FactorAttr", vector = factor(c(TRUE,TRUE,FALSE, FALSE))),
atributoDataset(name = "FactorAttr2", vector = factor(c(FALSE,FALSE,TRUE, FALSE))),
atributoDataset(name = "NumericAttr2", vector = c(28, 5, 19, 24)),
atributoDataset(name = "NumericAttr3", vector = c(4, 5, 6, 7))
))
correlation(dataset)
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenise()
build_vignettes()
devtools::build_vignettes()
